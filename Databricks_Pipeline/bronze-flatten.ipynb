{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42c1a7e5-8aef-495f-8ff5-a3875140f2d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17584a8e-9dc9-42f5-a099-de0bb2c89dd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = \"wasbs://bronze@ilab9788543873.blob.core.windows.net\",\n",
    "  mount_point = \"/mnt/ilab9788543873/bronze\",\n",
    "  extra_configs = {\"fs.azure.account.key.ilab9788543873.blob.core.windows.net\":\"TAyrrfaiCQ86vkgSXyStufowrMVdk4T45mVw6TNcFFJocR6pTXy6ZMSUUTeeh5FpNTsBVAbVqdwk+AStHA3x1g==\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fe10228-643c-4a21-ac97-d1247d7c3fd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as json\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"dbfs:/mnt/ilab9788543873/bronze/raw_output.json\"\n",
    "\n",
    "# 1. Read the JSON file into a DataFrame\n",
    "# Load JSON data\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data_json = json.load(file)\n",
    "    # Indicating that the data was loaded successfully\n",
    "    load_success = True\n",
    "except json.JSONDecodeError as e:\n",
    "    load_success = False\n",
    "    load_error = str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e03e110-050d-4aad-8e2a-6e5935d3a0f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing lists or dictionaries: ['biblio', 'legal_status', 'abstract', 'claims', 'description']\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data_json)\n",
    "\n",
    "def find_non_primitive_columns(df):\n",
    "    non_primitive_columns = []\n",
    "    for col in df.columns:\n",
    "        # Find the first non-null entry in the column\n",
    "        non_null_entries = df[col].dropna().values\n",
    "        if len(non_null_entries) > 0:\n",
    "            first_non_null = non_null_entries[0]\n",
    "            # Check if it's a list or dictionary\n",
    "            if isinstance(first_non_null, (list, dict)):\n",
    "                non_primitive_columns.append(col)\n",
    "    return non_primitive_columns\n",
    "\n",
    "# Example usage:\n",
    "non_primitive_cols = find_non_primitive_columns(df)\n",
    "print(\"Columns containing lists or dictionaries:\", non_primitive_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67b21ae4-205e-4a9b-9235-466bbd1fd5c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1.0 Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1b4045a-f26b-4226-b595-ede4e0c3df96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_json(file_path)\n",
    "\n",
    "abstract_df = data[['lens_id', 'abstract']].copy()\n",
    "\n",
    "def extract_text(abstract_item):\n",
    "    # If the item is a dictionary, return the 'text' value\n",
    "    if isinstance(abstract_item, dict):\n",
    "        return abstract_item.get('text', None)  # Use .get() to safely retrieve the key\n",
    "    # If the item is a list, you can decide how you want to handle this.\n",
    "    # For example, you can return the first item's 'text' value.\n",
    "    elif isinstance(abstract_item, list) and len(abstract_item) > 0:\n",
    "        return abstract_item[0].get('text', None)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "abstract_df['text'] = abstract_df['abstract'].apply(extract_text)\n",
    "abstract_df = abstract_df.drop(columns=['abstract'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f851470e-6064-4912-8842-d36e38ff66c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2.0 Bibliographic Application Reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8d485a1-725c-4d09-88a7-871c9d5d90db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "biblio_app_ref_df = data[['lens_id']].copy()\n",
    "biblio_app_ref = data['biblio'].apply(lambda x: x.get('application_reference', {})).apply(pd.Series)\n",
    "\n",
    "# Adding them to our DataFrame\n",
    "biblio_app_ref_df = pd.concat([biblio_app_ref_df, biblio_app_ref], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "242802cc-ca45-4db4-8bcc-06b5ce71b4a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lens_id</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>doc_number</th>\n",
       "      <th>kind</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>041-096-994-434-303</td>\n",
       "      <td>US</td>\n",
       "      <td>201615237340</td>\n",
       "      <td>A</td>\n",
       "      <td>2016-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>018-076-028-631-459</td>\n",
       "      <td>US</td>\n",
       "      <td>201715489040</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>086-912-788-458-991</td>\n",
       "      <td>US</td>\n",
       "      <td>201715858486</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044-976-460-122-895</td>\n",
       "      <td>US</td>\n",
       "      <td>201715788948</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123-105-483-633-575</td>\n",
       "      <td>US</td>\n",
       "      <td>201715430408</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-02-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lens_id jurisdiction    doc_number kind        date\n",
       "0  041-096-994-434-303           US  201615237340    A  2016-08-15\n",
       "1  018-076-028-631-459           US  201715489040    A  2017-04-17\n",
       "2  086-912-788-458-991           US  201715858486    A  2017-12-29\n",
       "3  044-976-460-122-895           US  201715788948    A  2017-10-20\n",
       "4  123-105-483-633-575           US  201715430408    A  2017-02-10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biblio_app_ref_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a210f598-9742-4e63-9b63-c2b116e29735",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3.0 Bibliographic Cited By:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de7b8724-72da-4625-8f97-845ec757dd7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               lens_id  patent_count  \\\n0  041-096-994-434-303          14.0   \n0  041-096-994-434-303          14.0   \n0  041-096-994-434-303          14.0   \n0  041-096-994-434-303          14.0   \n0  041-096-994-434-303          14.0   \n\n                                   cited_document_id        cited_lens_id  \n0  {'jurisdiction': 'US', 'doc_number': '11416084...  101-652-338-808-281  \n0  {'jurisdiction': 'US', 'doc_number': '11409376...  095-034-701-034-046  \n0  {'jurisdiction': 'US', 'doc_number': '11630836...  003-580-552-488-28X  \n0  {'jurisdiction': 'US', 'doc_number': '11734706...  044-305-578-212-354  \n0  {'jurisdiction': 'US', 'doc_number': '11010940...  194-490-311-975-877  \n"
     ]
    }
   ],
   "source": [
    "biblio_cited_by_df = data[['lens_id']].copy()\n",
    "biblio_cited_by = data['biblio'].apply(lambda x: x.get('cited_by', {})).apply(pd.Series)\n",
    "biblio_cited_by_df['patent_count'] = biblio_cited_by['patent_count']\n",
    "\n",
    "# Handle the 'patents' list\n",
    "cited_by_patents = biblio_cited_by['patents'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "cited_by_patents_df = pd.DataFrame(cited_by_patents.tolist(), index=cited_by_patents.index)\n",
    "cited_by_patents_df = cited_by_patents_df.rename(columns={\n",
    "    'lens_id': 'cited_lens_id', \n",
    "    'document_id': 'cited_document_id'\n",
    "})\n",
    "\n",
    "# Combine lens_id with the patents data\n",
    "biblio_cited_by_df = biblio_cited_by_df.join(cited_by_patents_df, how='outer')\n",
    "\n",
    "print(biblio_cited_by_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dd1fd54-6510-4a56-bf04-b47d5c7bb7f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3.1 cited_document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84889d2f-055b-462a-89ca-0bff40f25496",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting nested columns from the 'cited_document_id'\n",
    "cited_document_id_df = biblio_cited_by_df['cited_document_id'].apply(pd.Series)\n",
    "\n",
    "# Rename columns for clarity\n",
    "cited_document_id_df = cited_document_id_df.rename(columns={\n",
    "    'jurisdiction': 'cited_jurisdiction',\n",
    "    'doc_number': 'cited_doc_number',\n",
    "    'kind': 'cited_kind'\n",
    "})\n",
    "\n",
    "# Drop the original 'cited_document_id' column\n",
    "biblio_cited_by_df = biblio_cited_by_df.drop(columns=['cited_document_id'])\n",
    "\n",
    "# Join the flattened columns to the original DataFrame\n",
    "biblio_cited_by_df = pd.concat([biblio_cited_by_df, cited_document_id_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0a2d722-64e1-4fc1-a263-e1f7cd178762",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4.0 classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f5a7892-4b30-4004-a93e-4566a2a271bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract the classifications list and expand it into its own DataFrame\n",
    "classifications_df = data['biblio'].apply(lambda x: x.get('classifications_cpc', {}).get('classifications', {})).explode().reset_index(drop=True)\n",
    "\n",
    "# Extract the 'symbol' from the classifications_df\n",
    "classifications_df = classifications_df.apply(lambda x: x.get('symbol') if isinstance(x, dict) else None)\n",
    "\n",
    "# Adding lens_id for reference\n",
    "classifications_df = pd.concat([data['lens_id'], classifications_df], axis=1)\n",
    "classifications_df.columns = ['lens_id', 'symbol']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea53e49a-06f7-4384-902a-afd4ec461850",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5.0 invention_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "303d65ac-24cd-4388-884e-f54bac44ff16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "invention_title_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'invention_title' from the nested dictionaries\n",
    "titles = data['biblio'].apply(lambda x: x.get('invention_title', [{}]))\n",
    "\n",
    "# Expanding the lists to rows and extracting the text\n",
    "exploded_titles = titles.explode().apply(lambda x: x.get('text') if isinstance(x, dict) else None)\n",
    "\n",
    "# Combine the lens_id and exploded titles\n",
    "invention_title_df = pd.concat([invention_title_df.reset_index(drop=True), exploded_titles.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "invention_title_df.columns = ['lens_id', 'invention_title']\n",
    "\n",
    "# Remove rows where 'invention_title' is None or NaN\n",
    "invention_title_df = invention_title_df.dropna(subset=['invention_title']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cecdcccf-71cc-401e-a881-7ad96fbc9f98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6.1 applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48b65968-6334-4b42-b9ce-4a77ce2205de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "applicants_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'applicants' from the nested dictionaries\n",
    "applicants = data['biblio'].apply(lambda x: x.get('parties', {}).get('applicants', [{}]))\n",
    "\n",
    "# Further extracting 'extracted_name' and its 'value'\n",
    "applicants_names = applicants.apply(lambda x: [y.get('extracted_name', {}).get('value') for y in x if isinstance(y, dict) and 'extracted_name' in y])\n",
    "\n",
    "# Expanding the lists to rows\n",
    "exploded_applicants = applicants_names.explode()\n",
    "\n",
    "# Combine the lens_id and exploded applicant names\n",
    "applicants_df = pd.concat([applicants_df.reset_index(drop=True), exploded_applicants.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "applicants_df.columns = ['lens_id', 'applicant_name']\n",
    "\n",
    "# Remove rows where 'applicant_name' is None or NaN\n",
    "applicants_df = applicants_df.dropna(subset=['applicant_name']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b0105e0-4505-427f-8886-aab16f0de466",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lens_id</th>\n",
       "      <th>applicant_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>041-096-994-434-303</td>\n",
       "      <td>ALEGEUS TECH LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>018-076-028-631-459</td>\n",
       "      <td>INTEL CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>086-912-788-458-991</td>\n",
       "      <td>INTEL CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044-976-460-122-895</td>\n",
       "      <td>GOOGLE LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123-105-483-633-575</td>\n",
       "      <td>QUALCOMM INC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lens_id    applicant_name\n",
       "0  041-096-994-434-303  ALEGEUS TECH LLC\n",
       "1  018-076-028-631-459        INTEL CORP\n",
       "2  086-912-788-458-991        INTEL CORP\n",
       "3  044-976-460-122-895        GOOGLE LLC\n",
       "4  123-105-483-633-575      QUALCOMM INC"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applicants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b0287ca-9fda-49cb-97d6-5584aa463427",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6.2 inventors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc72c33f-eee0-48af-8c16-efe138c74f40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "inventors_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'inventors' from the nested dictionaries\n",
    "inventors = data['biblio'].apply(lambda x: x.get('parties', {}).get('inventors', [{}]))\n",
    "\n",
    "# Expanding the lists to rows and extracting the name value\n",
    "exploded_inventors = inventors.explode().apply(lambda x: x.get('extracted_name', {}).get('value') if isinstance(x, dict) else None)\n",
    "\n",
    "# Combine the lens_id and exploded inventors\n",
    "inventors_df = pd.concat([inventors_df.reset_index(drop=True), exploded_inventors.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "inventors_df.columns = ['lens_id', 'inventor_name']\n",
    "\n",
    "# Remove rows where 'inventor_name' is None or NaN\n",
    "inventors_df = inventors_df.dropna(subset=['inventor_name']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d02aeaa-a4b7-499d-82dd-3f634e17ce46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6.3 owners_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a584927-42c7-41d3-9478-a95562ca0474",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "owners_all_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'owners_all' from the nested dictionaries\n",
    "owners_all = data['biblio'].apply(lambda x: x.get('parties', {}).get('owners_all', [{}]))\n",
    "\n",
    "# Expanding the lists to rows and extracting the name value, address, country, execution_date, and recorded_date\n",
    "exploded_owners_all = owners_all.explode().apply(lambda x: {\n",
    "    'owner_name': x.get('extracted_name', {}).get('value'),\n",
    "    'address': x.get('extracted_address'),\n",
    "    'country': x.get('extracted_country'),\n",
    "    'execution_date': x.get('execution_date'),\n",
    "    'recorded_date': x.get('recorded_date')\n",
    "} if isinstance(x, dict) else {})\n",
    "\n",
    "# Convert this Series of dictionaries into a DataFrame\n",
    "owners_all_details_df = pd.DataFrame(exploded_owners_all.tolist())\n",
    "\n",
    "# Combine the lens_id and exploded owners_all details\n",
    "owners_all_df = pd.concat([owners_all_df.reset_index(drop=True), owners_all_details_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove rows where all owner details are NaN or None\n",
    "owners_all_df = owners_all_df.dropna(subset=['owner_name', 'address', 'country', 'execution_date', 'recorded_date'], how='all').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2ae5502-81ac-4818-b860-17dc9bb42698",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 7.1 priority_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b728dd-a6e5-4788-b408-4b98b794c389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "priority_claims_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'claims' from the nested dictionaries within 'priority_claims'\n",
    "claims = data['biblio'].apply(lambda x: x.get('priority_claims', {}).get('claims', [{}]))\n",
    "\n",
    "# Expanding the lists to rows\n",
    "exploded_claims = claims.explode()\n",
    "\n",
    "# Convert this Series of dictionaries into a DataFrame\n",
    "claims_details_df = pd.DataFrame(exploded_claims.tolist())\n",
    "\n",
    "# Combine the lens_id and exploded claims details\n",
    "priority_claims_df = pd.concat([priority_claims_df.reset_index(drop=True), claims_details_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove rows where all claim details are NaN or None\n",
    "priority_claims_df = priority_claims_df.dropna(subset=['date', 'doc_number', 'jurisdiction', 'kind', 'sequence'], how='all').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b236a74c-0984-4bda-a481-d01bf1770b85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 7.2 earliest_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89b1d7ef-853d-436c-aa4a-145f4c2cb6b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "earliest_claim_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'earliest_claim' from the nested dictionaries within 'priority_claims'\n",
    "earliest_claim = data['biblio'].apply(lambda x: x.get('priority_claims', {}).get('earliest_claim', {}))\n",
    "\n",
    "# Convert this Series of dictionaries into a DataFrame\n",
    "earliest_claim_details_df = pd.DataFrame(earliest_claim.tolist())\n",
    "\n",
    "# Combine the lens_id and earliest_claim details\n",
    "earliest_claim_df = pd.concat([earliest_claim_df.reset_index(drop=True), earliest_claim_details_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove rows where 'date' is NaN or None\n",
    "earliest_claim_df = earliest_claim_df.dropna(subset=['date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bdd87aa-070b-475a-85bc-8dbbbd34bcd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 8.0 publication_reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf93d576-b217-4e24-8d20-0e4fa730c729",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "publication_reference_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting the 'publication_reference' from the nested dictionaries within 'biblio'\n",
    "pub_ref = data['biblio'].apply(lambda x: x.get('publication_reference', {}))\n",
    "\n",
    "# Convert this Series of dictionaries into a DataFrame\n",
    "pub_ref_details_df = pd.DataFrame(pub_ref.tolist())\n",
    "\n",
    "# Combine the lens_id and pub_ref details\n",
    "publication_reference_df = pd.concat([publication_reference_df.reset_index(drop=True), pub_ref_details_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove rows where all publication reference details are NaN or None\n",
    "publication_reference_df = publication_reference_df.dropna(subset=['date', 'doc_number', 'jurisdiction', 'kind'], how='all').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac812a3a-edeb-4b63-90c3-38c3a55b8722",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 9.0 reference_cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0617e3c-3704-4345-a407-83695cea37c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial DataFrame with lens_id\n",
    "references_cited_df = data[['lens_id']].copy()\n",
    "\n",
    "# Extracting 'citations' from the nested dictionaries within 'references_cited'\n",
    "citations = data['biblio'].apply(lambda x: x.get('references_cited', {}).get('citations', [{}]))\n",
    "\n",
    "# Explode the citations list\n",
    "exploded_citations = citations.explode().reset_index(drop=True)\n",
    "\n",
    "# Extract cited_phase, sequence, nplcit details\n",
    "references_cited_df['cited_phase'] = exploded_citations.apply(lambda x: x.get('cited_phase'))\n",
    "references_cited_df['sequence'] = exploded_citations.apply(lambda x: x.get('sequence'))\n",
    "references_cited_df['nplcit_lens_id'] = exploded_citations.apply(lambda x: x.get('nplcit', {}).get('lens_id'))\n",
    "references_cited_df['nplcit_text'] = exploded_citations.apply(lambda x: x.get('nplcit', {}).get('text'))\n",
    "\n",
    "# Extract details from patcit and expand patcit's document_id\n",
    "patcit_document_id = exploded_citations.apply(lambda x: x.get('patcit', {}).get('document_id', {})).apply(pd.Series)\n",
    "\n",
    "# Rename columns for clarity\n",
    "patcit_document_id.columns = ['patcit_' + col for col in patcit_document_id.columns]\n",
    "\n",
    "# Combine the DataFrames\n",
    "references_cited_df = pd.concat([references_cited_df.reset_index(drop=True), patcit_document_id.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Filter rows with no relevant details\n",
    "references_cited_df = references_cited_df.dropna(subset=['cited_phase', 'nplcit_lens_id', 'sequence'], how='all').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a887c453-4f1d-4708-9b3a-35e26ecec13d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 10.0 claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25a5fa74-3314-43b2-bac3-61b7d487006b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out non-list entries\n",
    "filtered_data = data[data['claims'].apply(lambda x: isinstance(x, list))]\n",
    "\n",
    "# Using a nested list comprehension to extract claim_texts\n",
    "claim_texts = filtered_data['claims'].apply(lambda claims: [claim.get('claim_text', [None])[0] for claim in claims if isinstance(claim, dict)])\n",
    "\n",
    "# Add lens_id and explode the lists to rows\n",
    "claims_df = pd.DataFrame({\n",
    "    'lens_id': filtered_data['lens_id'].repeat(claim_texts.apply(len)),\n",
    "    'claim_text': [text for texts in claim_texts for text in texts]\n",
    "})\n",
    "\n",
    "# Remove rows where 'claim_text' is None or NaN\n",
    "claims_df = claims_df.dropna(subset=['claim_text']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40859d83-327e-4665-8526-db0b0d525ea1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting the 'claim_text' from the nested structure\n",
    "def extract_claim_texts(claims_list):\n",
    "    if not isinstance(claims_list, list):\n",
    "        return []\n",
    "    claim_texts = []\n",
    "    for entry in claims_list:\n",
    "        if 'claims' in entry:\n",
    "            for claim in entry['claims']:\n",
    "                if 'claim_text' in claim:\n",
    "                    claim_texts.extend(claim['claim_text'])\n",
    "    return claim_texts\n",
    "\n",
    "data['claim_texts'] = data['claims'].apply(extract_claim_texts)\n",
    "\n",
    "# Now, we'll explode the claim_texts to have one row per claim_text\n",
    "exploded_data = data.explode('claim_texts')[['lens_id', 'claim_texts']]\n",
    "exploded_data = exploded_data.rename(columns={'claim_texts': 'claim_text'})\n",
    "\n",
    "# Checking the structure of the resulting dataframe\n",
    "claims_df = exploded_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a86b50c-a69d-4e6a-89a5-4958d3839338",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 11.0 description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65b76370-c247-42fc-a141-5f0270fc2a9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting the 'text' from the 'description' column\n",
    "def extract_description_text(description):\n",
    "    if isinstance(description, dict) and 'text' in description:\n",
    "        return description['text']\n",
    "    return None\n",
    "\n",
    "data['description_text'] = data['description'].apply(extract_description_text)\n",
    "\n",
    "# Now, you'll have a new column named 'description_text' containing the descriptions\n",
    "descriptions_df = data[['lens_id', 'description_text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "396bd2e1-afaa-44fd-aae0-24723ee0eb9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 12.0 legal_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59b3202d-60b8-46e2-85fb-e9cb9eceedaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting the 'grant_date', 'granted', and 'patent_status' from the 'legal_status' column\n",
    "def extract_grant_date(legal_status):\n",
    "    if isinstance(legal_status, dict) and 'grant_date' in legal_status:\n",
    "        return legal_status['grant_date']\n",
    "    return None\n",
    "\n",
    "def extract_granted(legal_status):\n",
    "    if isinstance(legal_status, dict) and 'granted' in legal_status:\n",
    "        return legal_status['granted']\n",
    "    return None\n",
    "\n",
    "def extract_patent_status(legal_status):\n",
    "    if isinstance(legal_status, dict) and 'patent_status' in legal_status:\n",
    "        return legal_status['patent_status']\n",
    "    return None\n",
    "\n",
    "data['grant_date'] = data['legal_status'].apply(extract_grant_date)\n",
    "data['granted'] = data['legal_status'].apply(extract_granted)\n",
    "data['patent_status'] = data['legal_status'].apply(extract_patent_status)\n",
    "\n",
    "# Now, you'll have three new columns named 'grant_date', 'granted', and 'patent_status'\n",
    "legal_status_df = data[['lens_id', 'grant_date', 'granted', 'patent_status']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18a51b59-82e8-48f7-b218-2ba2322d76b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 13.0 df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d493b96-0789-43b0-8328-3de41a4e5166",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_main = data[['lens_id','date_published', 'doc_number', 'jurisdiction', 'kind', 'lang']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ae52d63-6941-4f6c-8194-27e82b4c9b2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6863999d-eb4d-4b9d-8e99-a21af5e8dabf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Starting with df_main as the base\n",
    "merged_df = df_main\n",
    "\n",
    "# List of all dataframes to merge\n",
    "dfs_to_merge = [abstract_df, biblio_cited_by_df, classifications_df, invention_title_df, \n",
    "                applicants_df, inventors_df, owners_all_df, priority_claims_df, \n",
    "                earliest_claim_df, publication_reference_df, references_cited_df, \n",
    "                claims_df, descriptions_df, legal_status_df]\n",
    "\n",
    "# Iteratively merge dataframes on lens_id\n",
    "for df in dfs_to_merge:\n",
    "    merged_df = pd.merge(merged_df, df, on='lens_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c51416cd-1eb0-4272-b300-15c0cd4dd4d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a6f3358-5a22-4c51-a44c-e94bc7f6ba9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import io\n",
    "\n",
    "# Your Azure Blob Storage credentials\n",
    "account_name = 'ilab9788543873'\n",
    "account_key = 'TAyrrfaiCQ86vkgSXyStufowrMVdk4T45mVw6TNcFFJocR6pTXy6ZMSUUTeeh5FpNTsBVAbVqdwk+AStHA3x1g=='\n",
    "container_name = 'silver'\n",
    "\n",
    "# Initialize BlobServiceClient\n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "\n",
    "# List of dataframes with their respective names\n",
    "dfs = {\n",
    "    'main': df_main,\n",
    "    'abstract': abstract_df,\n",
    "    'biblio_cited_by': biblio_cited_by_df,\n",
    "    'classifications': classifications_df,\n",
    "    'invention_title': invention_title_df,\n",
    "    'applicants': applicants_df,\n",
    "    'inventors': inventors_df,\n",
    "    'owners_all': owners_all_df,\n",
    "    'priority_claims': priority_claims_df,\n",
    "    'earliest_claim': earliest_claim_df,\n",
    "    'publication_reference': publication_reference_df,\n",
    "    'references_cited': references_cited_df,\n",
    "    'claims': claims_df,\n",
    "    'descriptions': descriptions_df,\n",
    "    'legal_status': legal_status_df\n",
    "}\n",
    "\n",
    "# Loop through each DataFrame and upload it to Azure Blob Storage\n",
    "for blob_name, df in dfs.items():\n",
    "    # Convert the DataFrame to a Parquet byte stream\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Create a blob client and upload the byte stream\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=f\"{blob_name}.parquet\")\n",
    "    \n",
    "    # Upload data\n",
    "    blob_client.upload_blob(buffer.getvalue(), overwrite=True, blob_type=\"BlockBlob\")\n",
    "    print(f\"{blob_name}.parquet uploaded to Azure Blob Storage\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze-flatten",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
